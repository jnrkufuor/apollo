{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_RH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37419588e3b74447b24ce643e2237509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1ddf234ee73d4f61b8a79ca60d5bef66",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db1d773053d844dcb38de62e5f43246a",
              "IPY_MODEL_38299a045bf347a9874e9d97dada8fb3"
            ]
          }
        },
        "1ddf234ee73d4f61b8a79ca60d5bef66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db1d773053d844dcb38de62e5f43246a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_585f128cbd734c798bd1689200c05645",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 432176557,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 432176557,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bc58799fc4545eabd3169fa10c66aeb"
          }
        },
        "38299a045bf347a9874e9d97dada8fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_46a503a674eb4015a0595ebe7f10402b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 432M/432M [00:21&lt;00:00, 19.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_674d5eadece04e81ac10c7c3e5c9caa2"
          }
        },
        "585f128cbd734c798bd1689200c05645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bc58799fc4545eabd3169fa10c66aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46a503a674eb4015a0595ebe7f10402b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "674d5eadece04e81ac10c7c3e5c9caa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jnrkufuor/apollo/blob/Ryan/NER_RH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6t6hNXOGj1e"
      },
      "source": [
        "## 1. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5ZuA0rtr7_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8950cfa3-afb9-44b8-e42c-79821be57610"
      },
      "source": [
        "# install flair\n",
        "!pip install flair\n",
        "\n",
        "# load basic packages\n",
        "import pandas as pd\n",
        "from itertools import combinations, product\n",
        "import string\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# load Flair and NLTK\n",
        "import torch\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from nltk import tokenize\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# is cuda available?\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/3a/1b46a0220d6176b22bcb9336619d1731301bc2c75fa926a9ef953e6e4d58/flair-0.8.0.post1-py3-none-any.whl (284kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 22.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 29.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30kB 30.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 33.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51kB 33.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 61kB 36.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 71kB 22.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 92kB 21.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 102kB 21.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 112kB 21.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 122kB 21.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133kB 21.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143kB 21.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 153kB 21.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 163kB 21.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 174kB 21.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 184kB 21.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 194kB 21.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 204kB 21.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 215kB 21.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 225kB 21.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 235kB 21.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 245kB 21.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 256kB 21.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 266kB 21.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 276kB 21.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 21.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/06/e5c80e2e0f979628d47345efba51f7ba386fe95963b11c594209085f5a9b/ftfy-5.9.tar.gz (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.7MB/s \n",
            "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/02/be/4dd30d56a0a19619deb9bf41ba8202709fa83b1b301b876572cd6dc38117/konoha-4.6.4-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.41.1)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/91/77/3f0f53856e86af32b1d3c86652815277f7b5f880002584eb30db115b6df5/bpemb-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 45.2MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading https://files.pythonhosted.org/packages/81/db/6127470a04b6f9de82e4e8d55d9b971b7ed9d6e04a0ef91883f2e15d4078/huggingface_hub-0.0.6-py3-none-any.whl\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/73/994edfcba74443146c84b91921fcc269374354118d4f452fb0c54c1cbb12/Deprecated-1.2.12-py2.py3-none-any.whl\n",
            "Collecting torch<=1.7.1,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 23kB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 47.7MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 1.5MB/s \n",
            "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Collecting gdown==3.12.2\n",
            "  Downloading https://files.pythonhosted.org/packages/50/21/92c3cfe56f5c0647145c4b0083d0733dd4890a057eb100a8eeddf949ffe9/gdown-3.12.2.tar.gz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n",
            "Collecting transformers>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bb/52c052a01bfd62d4f8038a29c15612eb144b99c11d1f082a7adb5510c22b/transformers-4.4.0-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 50.1MB/s \n",
            "\u001b[?25hCollecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.7.2)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Collecting requests<3.0.0,>=2.25.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.1->flair) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->flair) (3.0.12)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.7.1,>=1.5.0->flair) (3.7.4.3)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.1MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (20.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.25.1->konoha<5.0.0,>=4.0.0->flair) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.25.1->konoha<5.0.0,>=4.0.0->flair) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.25.1->konoha<5.0.0,>=4.0.0->flair) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.25.1->konoha<5.0.0,>=4.0.0->flair) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-cp37-none-any.whl size=9693 sha256=04a93ab760d643e92b1ddf687f9e898f5528aa776018945eb7c2db1e7d30d64b\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/d0/d7/d9983facc6f2775411803e0e2d30ebf98efbf2fc6e57701e09\n",
            "Successfully built gdown\n",
            "Building wheels for collected packages: segtok, ftfy, mpld3, sqlitedict, langdetect, overrides, sacremoses\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp37-none-any.whl size=25019 sha256=e7c6c76a24647b647b12fd87d36a18ab5fd032f3730df9882d63a428d298f921\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.9-cp37-none-any.whl size=46451 sha256=83796fa7d596eb3d83980bddcd29eb0ecf32b8efbd51675b93685e2278bda871\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/2e/f0/b07196e8c929114998f0316894a61c752b63bfa3fdd50d2fc3\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp37-none-any.whl size=116679 sha256=a97864ee416a72b0d7f230996e26311c5d5b47984865ecb65d362a088a0e8707\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp37-none-any.whl size=14376 sha256=2ec93eb19d0d5af4d193d191ab24d45e3abdb2e51425a81efc43edfb375ed26b\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp37-none-any.whl size=993193 sha256=fa18f1da1da4b9a47cc98a2990c14d17a9bf16a385f2b8a5b8504482548e23aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10174 sha256=754a767b888005ce5bdd0829eedc0e6f530103fd034761c5dd0f6b1412ab2b5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=7fc62c96cb6cc967c76e7946cdb271697c98ac189547885f2c32ba8c15e4dfe1\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built segtok ftfy mpld3 sqlitedict langdetect overrides sacremoses\n",
            "\u001b[31mERROR: torchvision 0.9.0+cu101 has requirement torch==1.8.0, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: segtok, ftfy, overrides, requests, konoha, sentencepiece, bpemb, mpld3, huggingface-hub, deprecated, torch, janome, sqlitedict, gdown, sacremoses, tokenizers, transformers, langdetect, flair\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "  Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "Successfully installed bpemb-0.3.2 deprecated-1.2.12 flair-0.8.0.post1 ftfy-5.9 gdown-3.12.2 huggingface-hub-0.0.6 janome-0.4.1 konoha-4.6.4 langdetect-1.0.8 mpld3-0.3 overrides-3.1.0 requests-2.25.1 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.1 torch-1.7.1 transformers-4.4.0\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tTkOuVyGqJE"
      },
      "source": [
        "## 2. Load Flair NER model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr-vGUuDsoSV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186,
          "referenced_widgets": [
            "37419588e3b74447b24ce643e2237509",
            "1ddf234ee73d4f61b8a79ca60d5bef66",
            "db1d773053d844dcb38de62e5f43246a",
            "38299a045bf347a9874e9d97dada8fb3",
            "585f128cbd734c798bd1689200c05645",
            "9bc58799fc4545eabd3169fa10c66aeb",
            "46a503a674eb4015a0595ebe7f10402b",
            "674d5eadece04e81ac10c7c3e5c9caa2"
          ]
        },
        "outputId": "fb37d71b-c2ae-42b5-c54e-41ef34366fa7"
      },
      "source": [
        "#Load NER Model\n",
        "tagger = SequenceTagger.load('ner')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-16 18:16:27,783 --------------------------------------------------------------------------------\n",
            "2021-03-16 18:16:27,784 The model key 'ner' now maps to 'https://huggingface.co/flair/ner-english' on the HuggingFace ModelHub\n",
            "2021-03-16 18:16:27,786  - The most current version of the model is automatically downloaded from there.\n",
            "2021-03-16 18:16:27,787  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/ner/en-ner-conll03-v0.4.pt)\n",
            "2021-03-16 18:16:27,788 --------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37419588e3b74447b24ce643e2237509",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=432176557.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2021-03-16 18:16:49,084 loading file /root/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnu5oi_lGuy_"
      },
      "source": [
        "## 3. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C-mOT1Ks-TM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "485372ea-a7ac-491d-ef01-980b9613c965"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/My Drive/googlenews1000.csv')\n",
        "#Above two lines may have to be changed to import your data depending on where it is\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>media</th>\n",
              "      <th>date</th>\n",
              "      <th>datetime</th>\n",
              "      <th>desc</th>\n",
              "      <th>link</th>\n",
              "      <th>img</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>STUCK IN WALMART PARKING lot after Colorado storm</td>\n",
              "      <td>FOX31 Denver</td>\n",
              "      <td>1 hour ago</td>\n",
              "      <td>2021-03-15 22:26:32.753586</td>\n",
              "      <td>Several drivers were forced into a Walmart par...</td>\n",
              "      <td>https://kdvr.com/news/local/drivers-spend-hour...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>AURORA, Colo. (KDVR) — The historic snowstorm ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Suspect wanted in fatal Monkey Junction Walmar...</td>\n",
              "      <td>Home - WSFX</td>\n",
              "      <td>1 hour ago</td>\n",
              "      <td>2021-03-15 22:26:32.755743</td>\n",
              "      <td>Laron Lee Carter is wanted by the NHC Sheriff'...</td>\n",
              "      <td>https://foxwilmington.com/local-news/suspect-w...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>According to a spokesperson for the New Hanove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Walmart Theft Investigation Turns Into Chase A...</td>\n",
              "      <td>KVRR</td>\n",
              "      <td>1 hour ago</td>\n",
              "      <td>2021-03-15 22:26:32.757773</td>\n",
              "      <td>— Two people are arrested after a chase where ...</td>\n",
              "      <td>https://www.kvrr.com/2021/03/15/walmart-theft-...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>Walmart Theft Investigation Turns Into Chase A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Walmart Calls Ex-Worker's 'Stonewalling' Claim...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1 hour ago</td>\n",
              "      <td>2021-03-15 22:26:32.759685</td>\n",
              "      <td>Law360 (March 15, 2021, 5:49 PM EDT) -- An ex-...</td>\n",
              "      <td>https://www.law360.com/retail/articles/1364916...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>Law360 (March 15, 2021, 5:49 PM EDT) -- An ex-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Three wanted for questioning in Walmart shopli...</td>\n",
              "      <td>wgxa.tv</td>\n",
              "      <td>1 hour ago</td>\n",
              "      <td>2021-03-15 22:26:32.761621</td>\n",
              "      <td>HOUSTON COUNTY, Ga. -- Perry police are lookin...</td>\n",
              "      <td>https://wgxa.tv/news/local/three-wanted-for-qu...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>9</td>\n",
              "      <td>Programmable Metallization Cell Market 2021 In...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8 hours ago</td>\n",
              "      <td>2021-03-15 15:28:20.158326</td>\n",
              "      <td>Axon Technologies; Micron Technology; Fujitsu ...</td>\n",
              "      <td>https://soccernurds.com/uncategorized/2268339/...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>Industry Growth Insights (IGI) has published a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0</td>\n",
              "      <td>Tampa International Airport sees spike in trav...</td>\n",
              "      <td>WFLA</td>\n",
              "      <td>16 mins ago</td>\n",
              "      <td>2021-03-15 23:12:21.719311</td>\n",
              "      <td>This past Saturday airport officials say they ...</td>\n",
              "      <td>https://www.wfla.com/community/health/coronavi...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>TAMPA, Fla. (WFLA) – People are taking flight ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1</td>\n",
              "      <td>Local Wis. health officials urge against trave...</td>\n",
              "      <td>WMTV - NBC15</td>\n",
              "      <td>46 mins ago</td>\n",
              "      <td>2021-03-15 22:42:21.723116</td>\n",
              "      <td>MADISON, Wis. (WMTV) - With spring break right...</td>\n",
              "      <td>https://www.nbc15.com/2021/03/15/local-wis-hea...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>MADISON, Wis. (WMTV) - With spring break right...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>2</td>\n",
              "      <td>Oklahomans traveling for spring break despite ...</td>\n",
              "      <td>kjrh.com</td>\n",
              "      <td>50 mins ago</td>\n",
              "      <td>2021-03-15 22:38:21.726876</td>\n",
              "      <td>TULSA, Okla. — 2020 was a financial strain for...</td>\n",
              "      <td>https://www.kjrh.com/news/local-news/spring-br...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>TULSA, Okla. — 2020 was a financial strain for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>3</td>\n",
              "      <td>Travel agents weigh in on guidelines for trave...</td>\n",
              "      <td>YourErie</td>\n",
              "      <td>1 hour ago</td>\n",
              "      <td>2021-03-15 22:28:21.728984</td>\n",
              "      <td>There isn't a clear answer as to how travelers...</td>\n",
              "      <td>https://www.yourerie.com/health/coronavirus/yo...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>With the onset of spring break and the easing ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>999 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  ...                                            content\n",
              "0             0  ...  AURORA, Colo. (KDVR) — The historic snowstorm ...\n",
              "1             1  ...  According to a spokesperson for the New Hanove...\n",
              "2             2  ...  Walmart Theft Investigation Turns Into Chase A...\n",
              "3             3  ...  Law360 (March 15, 2021, 5:49 PM EDT) -- An ex-...\n",
              "4             4  ...                                                NaN\n",
              "..          ...  ...                                                ...\n",
              "994           9  ...  Industry Growth Insights (IGI) has published a...\n",
              "995           0  ...  TAMPA, Fla. (WFLA) – People are taking flight ...\n",
              "996           1  ...  MADISON, Wis. (WMTV) - With spring break right...\n",
              "997           2  ...  TULSA, Okla. — 2020 was a financial strain for...\n",
              "998           3  ...  With the onset of spring break and the easing ...\n",
              "\n",
              "[999 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr23mImdtw-a"
      },
      "source": [
        "#4. Remove pronouns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6I_f1s4t0Aa"
      },
      "source": [
        "\n",
        "pronouns = ['I', 'You', 'It', 'He', 'She', 'We', 'They']\n",
        "suffixes = [\"\", \"’m\", \"’re\", \"’s\", \"’ve\", \"’d\", \"'m\", \"'re\", \"'s\", \"'ve\", \"'d\", \"m\", \"re\", \"s\", \"ve\", \"d\"]\n",
        "\n",
        "contraptions = [(p, s) for p in pronouns for s in suffixes]\n",
        "\n",
        "df_contraptions = pd.DataFrame(contraptions, columns=['pronoun', 'suffix'])\n",
        "\n",
        "df_contraptions['contraption'] = df_contraptions.apply(lambda x: x['pronoun'] + x['suffix'], axis=1)\n",
        "\n",
        "contraptions = df_contraptions.contraption.values\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bYq2pkjG3du"
      },
      "source": [
        "## 4. Define NER function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is7TUzu4tGP0"
      },
      "source": [
        "# define function\n",
        "\n",
        "def get_ner_data(paragraph):\n",
        "    '''\n",
        "    - function to extract named entities from a paragraph\n",
        "    - returns two data frames:\n",
        "        - the first is a dataframe of all unique entities (persons and orgs)\n",
        "        - the second is the links between the entities\n",
        "    '''\n",
        "    \n",
        "    # remove newlines and odd characters\n",
        "    paragraph = re.sub('\\r', '', paragraph)\n",
        "    paragraph = re.sub('\\n', ' ', paragraph)\n",
        "    paragraph = re.sub(\"’s\", '', paragraph)\n",
        "    paragraph = re.sub(\"“\", '', paragraph)\n",
        "    paragraph = re.sub(\"”\", '', paragraph)\n",
        "\n",
        "    \n",
        "    # tokenise sentences\n",
        "    sentences = tokenize.sent_tokenize(paragraph)\n",
        "    sentences = [Sentence(sent) for sent in sentences]\n",
        "    \n",
        "    # predict named entities\n",
        "    for sent in sentences:\n",
        "        tagger.predict(sent)\n",
        "    \n",
        "    # collect sentence NER's to list of dictionaries\n",
        "    sent_dicts = [sentence.to_dict(tag_type='ner') for sentence in sentences]\n",
        "    \n",
        "    # collect entities and types\n",
        "    entities = []\n",
        "    types = []\n",
        "    for sent_dict in sent_dicts:\n",
        "        entities.extend([entity['text'] for entity in sent_dict['entities']])\n",
        "        types.extend([str(entity['labels'])[1:4] for entity in sent_dict['entities']])\n",
        "   #The above line is what I changed from the default notebook to get things working     \n",
        "    \n",
        "    # create dataframe of entities (nodes)\n",
        "    df_ner = pd.DataFrame(data={'entity': entities, 'type': types})\n",
        "    df_ner = df_ner[df_ner['type'].isin(['PER','ORG'])]\n",
        "    df_ner = df_ner[df_ner['entity'].map(lambda x: isinstance(x, str))]\n",
        "    df_ner = df_ner[~df_ner['entity'].isin(df_contraptions['contraption'].values)]\n",
        "    df_ner['entity'] = df_ner['entity'].map(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "    df_ner['entity'] = df_ner.apply(lambda x: x['entity'].split(' ')[len(x['entity'].split(' '))-1] if x['type']=='PER' else x['entity'], axis=1)\n",
        "    df_ner = df_ner.drop_duplicates().sort_values('entity')\n",
        "    \n",
        "    # get entity combinations\n",
        "    combs = list(combinations(df_ner['entity'], 2))\n",
        "    \n",
        "    # create dataframe of relationships (edges)\n",
        "    df_links = pd.DataFrame(data=combs, columns=['from', 'to'])\n",
        "    \n",
        "    return df_ner, df_links"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmsBFSmRG6g2"
      },
      "source": [
        "## 5. Apply function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKlapM-otNIT"
      },
      "source": [
        "#df['date'] = pd.to_datetime(df['date'])\n",
        "#day = '2021-01-24'\n",
        "#df_day = df[df['date']==pd.to_datetime(day)][['date', 'domain', 'title', 'content']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdNrmXWUU6F1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "6af799d5-10fa-4805-f235-fb238ac69af3"
      },
      "source": [
        "df_domain = df.groupby('media').agg({'content': 'count'}).reset_index()\n",
        "df_domain.columns = ['media', 'count']\n",
        "df_domain = df_domain.sort_values('count', ascending=False)\n",
        "dfd_small=df_domain.iloc[1:21,:]\n",
        "\n",
        "dfd_small\n",
        "\n",
        "# g2 = sns.barplot(data=dfd_small,\n",
        "#              x='count',\n",
        "#              y='Domain',\n",
        "#              dodge=False,\n",
        "#              orient='h',\n",
        "#              hue='count',\n",
        "#              palette='viridis')\n",
        "\n",
        "# g2.set_yticks([])\n",
        "# g2.set_title('Number of articles from each provider')\n",
        "# g2.set_xlabel('Count')\n",
        "# g2.set_ylabel('')\n",
        "# g2.set_xlim(0, max(dfd_small['count'])+150)\n",
        "# g2.legend_.remove()\n",
        "# g2.tick_params(labelsize=5)\n",
        "\n",
        "# for i in dfd_small.index:\n",
        "#             g2.text(df_domain.iloc[i]['count']+5, i+0.25, df_domain.iloc[i]['Domain'], fontsize=8)\n",
        "\n",
        "# sns.despine()\n",
        "# g2.get_figure().savefig('domain_plot.png', dpi=1000)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>media</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>SoccerNurds</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>Yahoo Finance</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>NeighborWebSJ</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>The Bisouv Network</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Bloomberg</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>State Reviewer</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>Murphy's Hockey Law</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>The Courier</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>The Baxter Report</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>Patch.com</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Fintech Zoom</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>BOV News</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>CNBC</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>KicksOnFire.com</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Bankrate.com</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>Motley Fool</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>MarketWatch</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>HousingWire</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>The InvestChronicle</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>Yahoo News</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   media  count\n",
              "233          SoccerNurds     23\n",
              "325        Yahoo Finance     22\n",
              "183        NeighborWebSJ     22\n",
              "251   The Bisouv Network     14\n",
              "21             Bloomberg      8\n",
              "236       State Reviewer      8\n",
              "172  Murphy's Hockey Law      7\n",
              "253          The Courier      7\n",
              "250    The Baxter Report      7\n",
              "200            Patch.com      6\n",
              "95          Fintech Zoom      6\n",
              "11              BOV News      6\n",
              "38                  CNBC      5\n",
              "150      KicksOnFire.com      5\n",
              "13          Bankrate.com      5\n",
              "169          Motley Fool      5\n",
              "159          MarketWatch      5\n",
              "118          HousingWire      4\n",
              "267  The InvestChronicle      4\n",
              "327           Yahoo News      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-0mpYVXDo_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b800242-18fa-4a47-ef50-28aa1fd137a0"
      },
      "source": [
        "df_ner = pd.DataFrame()\n",
        "df_links = pd.DataFrame()\n",
        "\n",
        "for content in tqdm(df['content']):\n",
        "  try:\n",
        "    df_ner_temp, df_links_temp = get_ner_data(content)\n",
        "\n",
        "    df_ner = df_ner.append(df_ner_temp)\n",
        "    df_links = df_links.append(df_links_temp)\n",
        "  except:\n",
        "    continue\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 999/999 [38:54<00:00,  2.34s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "J8M9F10MclpN",
        "outputId": "fff527a3-18de-436d-b3aa-a37e73082bb6"
      },
      "source": [
        "# praph=df['content'].iloc[1]\r\n",
        "# praph = re.sub('\\r', '', praph)\r\n",
        "# praph = re.sub('\\n', ' ', praph)\r\n",
        "# praph = re.sub(\"’s\", '', praph)\r\n",
        "# praph = re.sub(\"“\", '', praph)\r\n",
        "# praph = re.sub(\"”\", '', praph)\r\n",
        "\r\n",
        "    \r\n",
        "# # tokenise sentences\r\n",
        "# sentences = tokenize.sent_tokenize(praph)\r\n",
        "# sentences = [Sentence(sent) for sent in sentences]\r\n",
        "\r\n",
        "# ## predict named entities\r\n",
        "# for sent in sentences:\r\n",
        "#     tagger.predict(sent)\r\n",
        "    \r\n",
        "# # # collect sentence NER's to list of dictionaries\r\n",
        "# sent_dicts = [sentence.to_dict(tag_type='ner') for sentence in sentences]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# # # collect entities and types\r\n",
        "# entities = []\r\n",
        "# types = []\r\n",
        "# for sent_dict in sent_dicts:\r\n",
        "#     entities.extend([entity['text'] for entity in sent_dict['entities']])\r\n",
        "#     types.extend([str(entity['labels'])[1:4] for entity in sent_dict['entities']])\r\n",
        "\r\n",
        "# types"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entity</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Cabrera</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Stokes</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Thomas</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Uber</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Volvo</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tulsa International Airport</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Denny</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>East Central Region AAA</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Miller Travel</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Williams</td>\n",
              "      <td>PER</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13326 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         entity type\n",
              "11                      Cabrera  PER\n",
              "8                        Stokes  PER\n",
              "13                       Thomas  PER\n",
              "15                         Uber  PER\n",
              "9                         Volvo  ORG\n",
              "..                          ...  ...\n",
              "2   Tulsa International Airport  ORG\n",
              "5                         Denny  PER\n",
              "4       East Central Region AAA  ORG\n",
              "6                 Miller Travel  ORG\n",
              "3                      Williams  PER\n",
              "\n",
              "[13326 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwC4omiTVC7N"
      },
      "source": [
        "# 6. Remove plurals and possessives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K6wZ_wE_h8H"
      },
      "source": [
        "def remove_s(entity, entity_series):\n",
        "  if (entity[-1] == 's') & (entity[:-1] in entity_series):\n",
        "    return entity[:-1]\n",
        "  else:\n",
        "    return entity\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWCvgkUvB_Pj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "70a0e19f-5815-4ba4-b3e0-3d7a4d62a71d"
      },
      "source": [
        "df_links['to'] = df_links['to'].map(lambda x: remove_s(x, df_ner['entity'].values))\n",
        "df_links['from'] = df_links['from'].map(lambda x: remove_s(x, df_ner['entity'].values))\n",
        "df_ner['entity_cl'] = df_ner['entity'].map(lambda x: remove_s(x, df_ner['entity'].values))\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cabrera</td>\n",
              "      <td>Stokes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cabrera</td>\n",
              "      <td>Thomas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cabrera</td>\n",
              "      <td>Uber</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cabrera</td>\n",
              "      <td>Volvo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cabrera</td>\n",
              "      <td>Walmart</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Denny</td>\n",
              "      <td>Miller Travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Denny</td>\n",
              "      <td>William</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>East Central Region AAA</td>\n",
              "      <td>Miller Travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>East Central Region AAA</td>\n",
              "      <td>William</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Miller Travel</td>\n",
              "      <td>William</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1032368 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       from             to\n",
              "0                   Cabrera         Stokes\n",
              "1                   Cabrera         Thomas\n",
              "2                   Cabrera           Uber\n",
              "3                   Cabrera          Volvo\n",
              "4                   Cabrera        Walmart\n",
              "..                      ...            ...\n",
              "1                     Denny  Miller Travel\n",
              "2                     Denny        William\n",
              "3   East Central Region AAA  Miller Travel\n",
              "4   East Central Region AAA        William\n",
              "5             Miller Travel        William\n",
              "\n",
              "[1032368 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIjTpMfLc-2F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "79326c6b-c6cc-4806-b5e6-ddb653897df8"
      },
      "source": [
        "df_links[df_links['to'].str.contains('They')]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [from, to]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKJYOh3eVJoL"
      },
      "source": [
        "# 7. Export Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzCtT6aQ43-U"
      },
      "source": [
        "#df_ner.to_csv('/content/drive/My Drive/df_ner_att1.csv', index=False)\n",
        "#df_links.to_csv('/content/drive/My Drive/df_links_att1.csv', index=False)\n",
        "\n",
        "#Use the above two lines to write the critical dataframes to csv files in your \n",
        "#google drive account"
      ],
      "execution_count": 33,
      "outputs": []
    }
  ]
}